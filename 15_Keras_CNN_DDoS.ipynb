{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for DDoS intrusion detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(667)  # randomize\n",
    "\n",
    "testdata = pd.read_csv(\"DDoS2007_spounged.csv\", header=None)\n",
    "\n",
    "\n",
    "#X = traindata.iloc[:,0:42]\n",
    "#Y = traindata.iloc[:,0]\n",
    "y_ini = testdata.iloc[:,0]\n",
    "X_ini = testdata.iloc[:,1:42]\n",
    "\n",
    "scaler = Normalizer().fit(X_ini)\n",
    "X_tras = scaler.transform(X_ini) #X Transformed\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X = np.reshape(X_tras, (X_tras.shape[0],X_tras.shape[1],1))\n",
    "y = np.array(y_ini)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Conv1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(41, 1)))\n",
    "cnn.add(Conv1D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_size=(2)))\n",
    "cnn.add(Conv1D(128, 3, padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(Conv1D(128, 3, padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling1D(pool_size=(2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training (FIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700000 samples, validate on 300001 samples\n",
      "Epoch 1/15\n",
      "700000/700000 [==============================] - 560s 800us/step - loss: 0.3841 - acc: 0.8271 - val_loss: 0.3183 - val_acc: 0.8600\n",
      "Epoch 2/15\n",
      "700000/700000 [==============================] - 544s 777us/step - loss: 0.3118 - acc: 0.8652 - val_loss: 0.2786 - val_acc: 0.8784\n",
      "Epoch 3/15\n",
      "700000/700000 [==============================] - 549s 785us/step - loss: 0.2837 - acc: 0.8779 - val_loss: 0.2532 - val_acc: 0.8905\n",
      "Epoch 4/15\n",
      "700000/700000 [==============================] - 546s 780us/step - loss: 0.2652 - acc: 0.8866 - val_loss: 0.2385 - val_acc: 0.8977\n",
      "Epoch 5/15\n",
      "700000/700000 [==============================] - 550s 786us/step - loss: 0.2494 - acc: 0.8932 - val_loss: 0.2182 - val_acc: 0.9059\n",
      "Epoch 6/15\n",
      "700000/700000 [==============================] - 583s 833us/step - loss: 0.2359 - acc: 0.8983 - val_loss: 0.2218 - val_acc: 0.9038\n",
      "Epoch 7/15\n",
      "700000/700000 [==============================] - 575s 822us/step - loss: 0.2224 - acc: 0.9044 - val_loss: 0.2044 - val_acc: 0.9126\n",
      "Epoch 8/15\n",
      "700000/700000 [==============================] - 547s 781us/step - loss: 0.2141 - acc: 0.9065 - val_loss: 0.1827 - val_acc: 0.9194\n",
      "Epoch 9/15\n",
      "700000/700000 [==============================] - 390s 557us/step - loss: 0.2057 - acc: 0.9094 - val_loss: 0.1852 - val_acc: 0.9184\n",
      "Epoch 10/15\n",
      "700000/700000 [==============================] - 302s 432us/step - loss: 0.2034 - acc: 0.9111 - val_loss: 0.1823 - val_acc: 0.9190\n",
      "Epoch 11/15\n",
      "700000/700000 [==============================] - 526s 751us/step - loss: 0.1979 - acc: 0.9130 - val_loss: 0.1727 - val_acc: 0.9233\n",
      "Epoch 12/15\n",
      "700000/700000 [==============================] - 552s 789us/step - loss: 0.1942 - acc: 0.9145 - val_loss: 0.1728 - val_acc: 0.9231\n",
      "Epoch 13/15\n",
      "700000/700000 [==============================] - 556s 795us/step - loss: 0.1911 - acc: 0.9160 - val_loss: 0.1659 - val_acc: 0.9269\n",
      "Epoch 14/15\n",
      "700000/700000 [==============================] - 556s 794us/step - loss: 0.1880 - acc: 0.9169 - val_loss: 0.1647 - val_acc: 0.9281\n",
      "Epoch 15/15\n",
      "700000/700000 [==============================] - 553s 790us/step - loss: 0.1864 - acc: 0.9177 - val_loss: 0.1645 - val_acc: 0.9283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b9e9697630>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('BRNN Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.savefig('BRNN Model Accuracy.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy 0.9283\n",
      "recall 0.8491\n",
      "precision 0.9396\n",
      "f1score 0.8921\n",
      "confusion matrix [[189601   5710]\n",
      " [ 15793  88897]]\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_prob = cnn.predict(X_test)\n",
    "y_pred = (y_prob > 0.5).astype(np.int)\n",
    "np.savetxt(\"cnn.txt\", y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred , average=\"binary\")\n",
    "precision = precision_score(y_test, y_pred , average=\"binary\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\")\n",
    "\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy %.4f\" %accuracy)\n",
    "print(\"recall %.4f\" %recall)\n",
    "print(\"precision %.4f\" %precision)\n",
    "print(\"f1score %.4f\" %f1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"confusion matrix\", cm)\n",
    "print(\"----------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
